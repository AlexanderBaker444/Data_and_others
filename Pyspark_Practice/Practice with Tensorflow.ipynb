{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# split a univariate sequence into samples\n",
    "def split_sequence(sequence, n_steps):\n",
    "\tX, y = list(), list()\n",
    "\tfor i in range(len(sequence)):\n",
    "\t\t# find the end of this pattern\n",
    "\t\tend_ix = i + n_steps\n",
    "\t\t# check if we are beyond the sequence\n",
    "\t\tif end_ix > len(sequence)-1:\n",
    "\t\t\tbreak\n",
    "\t\t# gather input and output parts of the pattern\n",
    "\t\tseq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "\t\tX.append(seq_x)\n",
    "\t\ty.append(seq_y)\n",
    "\treturn array(X), array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import LSTM,Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10 20 30] 40\n",
      "[20 30 40] 50\n",
      "[30 40 50] 60\n",
      "[40 50 60] 70\n",
      "[50 60 70] 80\n",
      "[60 70 80] 90\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# univariate data preparation\n",
    "from numpy import array\n",
    " \n",
    "# split a univariate sequence into samples\n",
    "def split_sequence(sequence, n_steps):\n",
    "\tX, y = list(), list()\n",
    "\tfor i in range(len(sequence)):\n",
    "\t\t# find the end of this pattern\n",
    "\t\tend_ix = i + n_steps\n",
    "\t\t# check if we are beyond the sequence\n",
    "\t\tif end_ix > len(sequence)-1:\n",
    "\t\t\tbreak\n",
    "\t\t# gather input and output parts of the pattern\n",
    "\t\tseq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "\t\tX.append(seq_x)\n",
    "\t\ty.append(seq_y)\n",
    "\treturn array(X), array(y)\n",
    " \n",
    "# define input sequence\n",
    "raw_seq = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
    "# choose a number of time steps\n",
    "n_steps = 3\n",
    "n_features = 1\n",
    "# split into samples\n",
    "X, y = split_sequence(raw_seq, n_steps)\n",
    "# summarize the data\n",
    "for i in range(len(X)):\n",
    "\tprint(X[i], y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(n_steps, n_features)))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# reshape from [samples, timesteps] into [samples, timesteps, features]\n",
    "n_features = 1\n",
    "X = X.reshape((X.shape[0], X.shape[1], n_features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1aee53a61d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=200, verbose=0)\n",
    "# demonstrate prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x_input = array([70, 80, 90])\n",
    "x_input = x_input.reshape((1, n_steps, n_features)).astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[102.79045]]\n"
     ]
    }
   ],
   "source": [
    "yhat = model.predict(x_input, verbose=0)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import LSTM,Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['label'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-89fb74324319>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'iris.data'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3938\u001b[0m                                            \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3939\u001b[0m                                            \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3940\u001b[1;33m                                            errors=errors)\n\u001b[0m\u001b[0;32m   3941\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3942\u001b[0m     @rewrite_axis_style_signature('mapper', [('copy', True),\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3778\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3779\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3780\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3782\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   3810\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3811\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3812\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3813\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3814\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   4963\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'ignore'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4964\u001b[0m                 raise KeyError(\n\u001b[1;32m-> 4965\u001b[1;33m                     '{} not found in axis'.format(labels[mask]))\n\u001b[0m\u001b[0;32m   4966\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4967\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['label'] not found in axis\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('iris.data')\n",
    "X=df.drop('label',axis=1)\n",
    "y=df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 16 samples\n",
      "Epoch 1/150\n",
      "16/16 [==============================] - 1s 32ms/sample - loss: -2.1642 - accuracy: 0.5000\n",
      "Epoch 2/150\n",
      "16/16 [==============================] - 0s 431us/sample - loss: -2.3439 - accuracy: 0.5000\n",
      "Epoch 3/150\n",
      "16/16 [==============================] - 0s 310us/sample - loss: -2.5079 - accuracy: 0.5000\n",
      "Epoch 4/150\n",
      "16/16 [==============================] - 0s 398us/sample - loss: -2.7268 - accuracy: 0.5000\n",
      "Epoch 5/150\n",
      "16/16 [==============================] - 0s 371us/sample - loss: -2.9131 - accuracy: 0.5000\n",
      "Epoch 6/150\n",
      "16/16 [==============================] - 0s 436us/sample - loss: -3.0840 - accuracy: 0.5000\n",
      "Epoch 7/150\n",
      "16/16 [==============================] - 0s 401us/sample - loss: -3.2769 - accuracy: 0.5000\n",
      "Epoch 8/150\n",
      "16/16 [==============================] - 0s 436us/sample - loss: -3.4797 - accuracy: 0.5000\n",
      "Epoch 9/150\n",
      "16/16 [==============================] - 0s 377us/sample - loss: -3.6781 - accuracy: 0.5000\n",
      "Epoch 10/150\n",
      "16/16 [==============================] - 0s 312us/sample - loss: -3.8856 - accuracy: 0.5000\n",
      "Epoch 11/150\n",
      "16/16 [==============================] - 0s 312us/sample - loss: -4.0644 - accuracy: 0.5000\n",
      "Epoch 12/150\n",
      "16/16 [==============================] - 0s 304us/sample - loss: -4.2895 - accuracy: 0.5000\n",
      "Epoch 13/150\n",
      "16/16 [==============================] - 0s 249us/sample - loss: -4.4875 - accuracy: 0.5000\n",
      "Epoch 14/150\n",
      "16/16 [==============================] - 0s 312us/sample - loss: -4.6882 - accuracy: 0.5000\n",
      "Epoch 15/150\n",
      "16/16 [==============================] - 0s 312us/sample - loss: -4.9214 - accuracy: 0.5000\n",
      "Epoch 16/150\n",
      "16/16 [==============================] - 0s 374us/sample - loss: -5.1014 - accuracy: 0.5000\n",
      "Epoch 17/150\n",
      "16/16 [==============================] - 0s 323us/sample - loss: -5.3329 - accuracy: 0.5000\n",
      "Epoch 18/150\n",
      "16/16 [==============================] - 0s 318us/sample - loss: -5.5333 - accuracy: 0.5000\n",
      "Epoch 19/150\n",
      "16/16 [==============================] - 0s 249us/sample - loss: -5.7517 - accuracy: 0.5000\n",
      "Epoch 20/150\n",
      "16/16 [==============================] - 0s 249us/sample - loss: -6.0106 - accuracy: 0.5000\n",
      "Epoch 21/150\n",
      "16/16 [==============================] - 0s 312us/sample - loss: -6.2169 - accuracy: 0.5000\n",
      "Epoch 22/150\n",
      "16/16 [==============================] - 0s 312us/sample - loss: -6.4349 - accuracy: 0.5000\n",
      "Epoch 23/150\n",
      "16/16 [==============================] - 0s 559us/sample - loss: -6.7375 - accuracy: 0.5000\n",
      "Epoch 24/150\n",
      "16/16 [==============================] - 0s 444us/sample - loss: -6.9578 - accuracy: 0.5000\n",
      "Epoch 25/150\n",
      "16/16 [==============================] - 0s 368us/sample - loss: -7.2279 - accuracy: 0.5000\n",
      "Epoch 26/150\n",
      "16/16 [==============================] - 0s 373us/sample - loss: -7.5148 - accuracy: 0.5000\n",
      "Epoch 27/150\n",
      "16/16 [==============================] - 0s 324us/sample - loss: -7.8114 - accuracy: 0.5000\n",
      "Epoch 28/150\n",
      "16/16 [==============================] - 0s 341us/sample - loss: -8.0851 - accuracy: 0.5000\n",
      "Epoch 29/150\n",
      "16/16 [==============================] - 0s 312us/sample - loss: -8.4436 - accuracy: 0.5000\n",
      "Epoch 30/150\n",
      "16/16 [==============================] - 0s 312us/sample - loss: -8.7596 - accuracy: 0.5000\n",
      "Epoch 31/150\n",
      "16/16 [==============================] - 0s 316us/sample - loss: -9.0900 - accuracy: 0.5000\n",
      "Epoch 32/150\n",
      "16/16 [==============================] - 0s 327us/sample - loss: -9.4457 - accuracy: 0.5000\n",
      "Epoch 33/150\n",
      "16/16 [==============================] - 0s 265us/sample - loss: -9.8963 - accuracy: 0.5000\n",
      "Epoch 34/150\n",
      "16/16 [==============================] - 0s 312us/sample - loss: -10.2186 - accuracy: 0.5000\n",
      "Epoch 35/150\n",
      "16/16 [==============================] - 0s 382us/sample - loss: -10.6128 - accuracy: 0.5000\n",
      "Epoch 36/150\n",
      "16/16 [==============================] - 0s 312us/sample - loss: -11.0015 - accuracy: 0.5000\n",
      "Epoch 37/150\n",
      "16/16 [==============================] - 0s 249us/sample - loss: -11.4196 - accuracy: 0.5000\n",
      "Epoch 38/150\n",
      "16/16 [==============================] - 0s 376us/sample - loss: -11.8177 - accuracy: 0.5000\n",
      "Epoch 39/150\n",
      "16/16 [==============================] - 0s 311us/sample - loss: -12.1829 - accuracy: 0.5000\n",
      "Epoch 40/150\n",
      "16/16 [==============================] - 0s 290us/sample - loss: -12.6412 - accuracy: 0.5000\n",
      "Epoch 41/150\n",
      "16/16 [==============================] - 0s 309us/sample - loss: -12.9983 - accuracy: 0.5000\n",
      "Epoch 42/150\n",
      "16/16 [==============================] - 0s 312us/sample - loss: -13.4707 - accuracy: 0.5000\n",
      "Epoch 43/150\n",
      "16/16 [==============================] - 0s 312us/sample - loss: -13.8589 - accuracy: 0.5000\n",
      "Epoch 44/150\n",
      "16/16 [==============================] - 0s 312us/sample - loss: -14.3035 - accuracy: 0.5000\n",
      "Epoch 45/150\n",
      "16/16 [==============================] - 0s 312us/sample - loss: -14.7176 - accuracy: 0.5000\n",
      "Epoch 46/150\n",
      "16/16 [==============================] - 0s 374us/sample - loss: -15.0847 - accuracy: 0.5000\n",
      "Epoch 47/150\n",
      "16/16 [==============================] - 0s 341us/sample - loss: -15.5429 - accuracy: 0.5000\n",
      "Epoch 48/150\n",
      "16/16 [==============================] - 0s 361us/sample - loss: -15.9923 - accuracy: 0.5000\n",
      "Epoch 49/150\n",
      "16/16 [==============================] - 0s 308us/sample - loss: -16.4163 - accuracy: 0.5000\n",
      "Epoch 50/150\n",
      "16/16 [==============================] - 0s 312us/sample - loss: -16.7914 - accuracy: 0.5000\n",
      "Epoch 51/150\n",
      "16/16 [==============================] - 0s 374us/sample - loss: -17.2925 - accuracy: 0.5000\n",
      "Epoch 52/150\n",
      "16/16 [==============================] - 0s 312us/sample - loss: -17.6310 - accuracy: 0.5000\n",
      "Epoch 53/150\n",
      "16/16 [==============================] - 0s 254us/sample - loss: -18.1122 - accuracy: 0.5000\n",
      "Epoch 54/150\n",
      "16/16 [==============================] - 0s 249us/sample - loss: -18.5343 - accuracy: 0.5000\n",
      "Epoch 55/150\n",
      "16/16 [==============================] - 0s 231us/sample - loss: -19.0466 - accuracy: 0.5000\n",
      "Epoch 56/150\n",
      "16/16 [==============================] - 0s 312us/sample - loss: -19.4790 - accuracy: 0.5000\n",
      "Epoch 57/150\n",
      "16/16 [==============================] - 0s 312us/sample - loss: -19.8429 - accuracy: 0.5000\n",
      "Epoch 58/150\n",
      "16/16 [==============================] - 0s 312us/sample - loss: -20.2731 - accuracy: 0.5000\n",
      "Epoch 59/150\n",
      "16/16 [==============================] - 0s 189us/sample - loss: -20.7226 - accuracy: 0.5000\n",
      "Epoch 60/150\n",
      "16/16 [==============================] - 0s 248us/sample - loss: -20.9787 - accuracy: 0.5000\n",
      "Epoch 61/150\n",
      "16/16 [==============================] - 0s 245us/sample - loss: -21.2985 - accuracy: 0.5000\n",
      "Epoch 62/150\n",
      "16/16 [==============================] - 0s 249us/sample - loss: -21.6703 - accuracy: 0.5000\n",
      "Epoch 63/150\n",
      "16/16 [==============================] - 0s 312us/sample - loss: -21.9861 - accuracy: 0.5000\n",
      "Epoch 64/150\n",
      "16/16 [==============================] - 0s 249us/sample - loss: -22.2403 - accuracy: 0.5000\n",
      "Epoch 65/150\n",
      "16/16 [==============================] - 0s 249us/sample - loss: -22.5734 - accuracy: 0.5000\n",
      "Epoch 66/150\n",
      "16/16 [==============================] - 0s 312us/sample - loss: -22.8588 - accuracy: 0.5000\n",
      "Epoch 67/150\n",
      "16/16 [==============================] - 0s 249us/sample - loss: -23.1096 - accuracy: 0.5000\n",
      "Epoch 68/150\n",
      "16/16 [==============================] - 0s 200us/sample - loss: -23.3816 - accuracy: 0.5000\n",
      "Epoch 69/150\n",
      "16/16 [==============================] - 0s 257us/sample - loss: -23.6628 - accuracy: 0.5000\n",
      "Epoch 70/150\n",
      "16/16 [==============================] - 0s 313us/sample - loss: -23.9431 - accuracy: 0.5000\n",
      "Epoch 71/150\n",
      "16/16 [==============================] - 0s 312us/sample - loss: -24.2030 - accuracy: 0.5000\n",
      "Epoch 72/150\n",
      "16/16 [==============================] - 0s 325us/sample - loss: -24.4442 - accuracy: 0.5000\n",
      "Epoch 73/150\n",
      "16/16 [==============================] - 0s 249us/sample - loss: -24.6669 - accuracy: 0.5000\n",
      "Epoch 74/150\n",
      "16/16 [==============================] - 0s 280us/sample - loss: -24.9817 - accuracy: 0.5000\n",
      "Epoch 75/150\n",
      "16/16 [==============================] - 0s 253us/sample - loss: -25.1898 - accuracy: 0.5000\n",
      "Epoch 76/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 250us/sample - loss: -25.5008 - accuracy: 0.5000\n",
      "Epoch 77/150\n",
      "16/16 [==============================] - 0s 248us/sample - loss: -25.7131 - accuracy: 0.5000\n",
      "Epoch 78/150\n",
      "16/16 [==============================] - 0s 312us/sample - loss: -26.0406 - accuracy: 0.5000\n",
      "Epoch 79/150\n",
      "16/16 [==============================] - 0s 300us/sample - loss: -26.1127 - accuracy: 0.5000\n",
      "Epoch 80/150\n",
      "16/16 [==============================] - 0s 479us/sample - loss: -26.4064 - accuracy: 0.5000\n",
      "Epoch 81/150\n",
      "16/16 [==============================] - 0s 537us/sample - loss: -26.5317 - accuracy: 0.5000\n",
      "Epoch 82/150\n",
      "16/16 [==============================] - 0s 436us/sample - loss: -26.6591 - accuracy: 0.5000\n",
      "Epoch 83/150\n",
      "16/16 [==============================] - 0s 436us/sample - loss: -26.8284 - accuracy: 0.5000\n",
      "Epoch 84/150\n",
      "16/16 [==============================] - 0s 497us/sample - loss: -26.9325 - accuracy: 0.5000\n",
      "Epoch 85/150\n",
      "16/16 [==============================] - 0s 434us/sample - loss: -27.0837 - accuracy: 0.5000\n",
      "Epoch 86/150\n",
      "16/16 [==============================] - 0s 566us/sample - loss: -27.2291 - accuracy: 0.5000\n",
      "Epoch 87/150\n",
      "16/16 [==============================] - 0s 473us/sample - loss: -27.3560 - accuracy: 0.5000\n",
      "Epoch 88/150\n",
      "16/16 [==============================] - 0s 446us/sample - loss: -27.4459 - accuracy: 0.5000\n",
      "Epoch 89/150\n",
      "16/16 [==============================] - 0s 436us/sample - loss: -27.4729 - accuracy: 0.5000\n",
      "Epoch 90/150\n",
      "16/16 [==============================] - 0s 438us/sample - loss: -27.6066 - accuracy: 0.5000\n",
      "Epoch 91/150\n",
      "16/16 [==============================] - 0s 439us/sample - loss: -27.6793 - accuracy: 0.5000\n",
      "Epoch 92/150\n",
      "16/16 [==============================] - 0s 411us/sample - loss: -27.7175 - accuracy: 0.5000\n",
      "Epoch 93/150\n",
      "16/16 [==============================] - 0s 436us/sample - loss: -27.6536 - accuracy: 0.5000\n",
      "Epoch 94/150\n",
      "16/16 [==============================] - 0s 511us/sample - loss: -27.8084 - accuracy: 0.5000\n",
      "Epoch 95/150\n",
      "16/16 [==============================] - 0s 440us/sample - loss: -27.8529 - accuracy: 0.5000\n",
      "Epoch 96/150\n",
      "16/16 [==============================] - 0s 517us/sample - loss: -27.8841 - accuracy: 0.5000\n",
      "Epoch 97/150\n",
      "16/16 [==============================] - 0s 499us/sample - loss: -27.9391 - accuracy: 0.5000\n",
      "Epoch 98/150\n",
      "16/16 [==============================] - 0s 478us/sample - loss: -27.9659 - accuracy: 0.5000\n",
      "Epoch 99/150\n",
      "16/16 [==============================] - 0s 438us/sample - loss: -28.0068 - accuracy: 0.5000\n",
      "Epoch 100/150\n",
      "16/16 [==============================] - 0s 436us/sample - loss: -28.0396 - accuracy: 0.5000\n",
      "Epoch 101/150\n",
      "16/16 [==============================] - 0s 508us/sample - loss: -28.0671 - accuracy: 0.5000\n",
      "Epoch 102/150\n",
      "16/16 [==============================] - 0s 501us/sample - loss: -28.1017 - accuracy: 0.5000\n",
      "Epoch 103/150\n",
      "16/16 [==============================] - 0s 249us/sample - loss: -28.1347 - accuracy: 0.5000\n",
      "Epoch 104/150\n",
      "16/16 [==============================] - 0s 309us/sample - loss: -28.1674 - accuracy: 0.5000\n",
      "Epoch 105/150\n",
      "16/16 [==============================] - 0s 265us/sample - loss: -28.1899 - accuracy: 0.5000\n",
      "Epoch 106/150\n",
      "16/16 [==============================] - 0s 374us/sample - loss: -28.2302 - accuracy: 0.5000\n",
      "Epoch 107/150\n",
      "16/16 [==============================] - 0s 312us/sample - loss: -28.2610 - accuracy: 0.5000\n",
      "Epoch 108/150\n",
      "16/16 [==============================] - 0s 328us/sample - loss: -28.2825 - accuracy: 0.5000\n",
      "Epoch 109/150\n",
      "16/16 [==============================] - 0s 312us/sample - loss: -28.3222 - accuracy: 0.5000\n",
      "Epoch 110/150\n",
      "16/16 [==============================] - 0s 374us/sample - loss: -28.3550 - accuracy: 0.5000\n",
      "Epoch 111/150\n",
      "16/16 [==============================] - 0s 312us/sample - loss: -28.3772 - accuracy: 0.5000\n",
      "Epoch 112/150\n",
      "16/16 [==============================] - 0s 376us/sample - loss: -28.4151 - accuracy: 0.5000\n",
      "Epoch 113/150\n",
      "16/16 [==============================] - 0s 376us/sample - loss: -28.4355 - accuracy: 0.5000\n",
      "Epoch 114/150\n",
      "16/16 [==============================] - 0s 312us/sample - loss: -28.4745 - accuracy: 0.5000\n",
      "Epoch 115/150\n",
      "16/16 [==============================] - 0s 312us/sample - loss: -28.5037 - accuracy: 0.5000\n",
      "Epoch 116/150\n",
      "16/16 [==============================] - 0s 312us/sample - loss: -28.5343 - accuracy: 0.5000\n",
      "Epoch 117/150\n",
      "16/16 [==============================] - 0s 374us/sample - loss: -28.5603 - accuracy: 0.5000\n",
      "Epoch 118/150\n",
      "16/16 [==============================] - 0s 378us/sample - loss: -28.5872 - accuracy: 0.5000\n",
      "Epoch 119/150\n",
      "16/16 [==============================] - 0s 436us/sample - loss: -28.6220 - accuracy: 0.5000\n",
      "Epoch 120/150\n",
      "16/16 [==============================] - 0s 374us/sample - loss: -28.6429 - accuracy: 0.5000\n",
      "Epoch 121/150\n",
      "16/16 [==============================] - 0s 374us/sample - loss: -28.6881 - accuracy: 0.5000\n",
      "Epoch 122/150\n",
      "16/16 [==============================] - 0s 312us/sample - loss: -28.7142 - accuracy: 0.5000\n",
      "Epoch 123/150\n",
      "16/16 [==============================] - 0s 374us/sample - loss: -28.7418 - accuracy: 0.5000\n",
      "Epoch 124/150\n",
      "16/16 [==============================] - 0s 309us/sample - loss: -28.7788 - accuracy: 0.5000\n",
      "Epoch 125/150\n",
      "16/16 [==============================] - 0s 359us/sample - loss: -28.8107 - accuracy: 0.5000\n",
      "Epoch 126/150\n",
      "16/16 [==============================] - 0s 315us/sample - loss: -28.8291 - accuracy: 0.5000\n",
      "Epoch 127/150\n",
      "16/16 [==============================] - 0s 312us/sample - loss: -28.8866 - accuracy: 0.5000\n",
      "Epoch 128/150\n",
      "16/16 [==============================] - 0s 372us/sample - loss: -28.8946 - accuracy: 0.5000\n",
      "Epoch 129/150\n",
      "16/16 [==============================] - 0s 318us/sample - loss: -28.9309 - accuracy: 0.5000\n",
      "Epoch 130/150\n",
      "16/16 [==============================] - 0s 462us/sample - loss: -28.9676 - accuracy: 0.5000\n",
      "Epoch 131/150\n",
      "16/16 [==============================] - 0s 513us/sample - loss: -29.0232 - accuracy: 0.5000\n",
      "Epoch 132/150\n",
      "16/16 [==============================] - 0s 433us/sample - loss: -29.0364 - accuracy: 0.5000\n",
      "Epoch 133/150\n",
      "16/16 [==============================] - 0s 312us/sample - loss: -29.0831 - accuracy: 0.5000\n",
      "Epoch 134/150\n",
      "16/16 [==============================] - 0s 377us/sample - loss: -29.0991 - accuracy: 0.5000\n",
      "Epoch 135/150\n",
      "16/16 [==============================] - 0s 249us/sample - loss: -29.1352 - accuracy: 0.5000\n",
      "Epoch 136/150\n",
      "16/16 [==============================] - 0s 374us/sample - loss: -29.1626 - accuracy: 0.5000\n",
      "Epoch 137/150\n",
      "16/16 [==============================] - 0s 312us/sample - loss: -29.2160 - accuracy: 0.5000\n",
      "Epoch 138/150\n",
      "16/16 [==============================] - 0s 374us/sample - loss: -29.2361 - accuracy: 0.5000\n",
      "Epoch 139/150\n",
      "16/16 [==============================] - 0s 383us/sample - loss: -29.2838 - accuracy: 0.5000\n",
      "Epoch 140/150\n",
      "16/16 [==============================] - 0s 385us/sample - loss: -29.3169 - accuracy: 0.5000\n",
      "Epoch 141/150\n",
      "16/16 [==============================] - 0s 312us/sample - loss: -29.3374 - accuracy: 0.5000\n",
      "Epoch 142/150\n",
      "16/16 [==============================] - 0s 247us/sample - loss: -29.3701 - accuracy: 0.5000\n",
      "Epoch 143/150\n",
      "16/16 [==============================] - 0s 249us/sample - loss: -29.4197 - accuracy: 0.5000\n",
      "Epoch 144/150\n",
      "16/16 [==============================] - 0s 408us/sample - loss: -29.4915 - accuracy: 0.5000\n",
      "Epoch 145/150\n",
      "16/16 [==============================] - 0s 561us/sample - loss: -29.5048 - accuracy: 0.5000\n",
      "Epoch 146/150\n",
      "16/16 [==============================] - 0s 499us/sample - loss: -29.5118 - accuracy: 0.5000\n",
      "Epoch 147/150\n",
      "16/16 [==============================] - 0s 374us/sample - loss: -29.5339 - accuracy: 0.5000\n",
      "Epoch 148/150\n",
      "16/16 [==============================] - 0s 437us/sample - loss: -29.5498 - accuracy: 0.5000\n",
      "Epoch 149/150\n",
      "16/16 [==============================] - 0s 429us/sample - loss: -29.6247 - accuracy: 0.5000\n",
      "Epoch 150/150\n",
      "16/16 [==============================] - 0s 422us/sample - loss: -29.6337 - accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23356eefd30>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=2, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X, y, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "16/16 [==============================] - 0s 7ms/sample - loss: -29.7280 - accuracy: 0.5000\n",
      "Accuracy: 50.00\n"
     ]
    }
   ],
   "source": [
    "_, accuracy = model.evaluate(X, y)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 16 samples\n",
      "Epoch 1/150\n",
      "16/16 [==============================] - 1s 82ms/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 2/150\n",
      "16/16 [==============================] - 0s 625us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 3/150\n",
      "16/16 [==============================] - 0s 646us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 4/150\n",
      "16/16 [==============================] - 0s 563us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 5/150\n",
      "16/16 [==============================] - 0s 623us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 6/150\n",
      "16/16 [==============================] - 0s 562us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 7/150\n",
      "16/16 [==============================] - 0s 563us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 8/150\n",
      "16/16 [==============================] - 0s 564us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 9/150\n",
      "16/16 [==============================] - 0s 559us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 10/150\n",
      "16/16 [==============================] - 0s 571us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 11/150\n",
      "16/16 [==============================] - 0s 566us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 12/150\n",
      "16/16 [==============================] - 0s 561us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 13/150\n",
      "16/16 [==============================] - 0s 614us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 14/150\n",
      "16/16 [==============================] - 0s 561us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 15/150\n",
      "16/16 [==============================] - 0s 844us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 16/150\n",
      "16/16 [==============================] - 0s 624us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 17/150\n",
      "16/16 [==============================] - 0s 565us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 18/150\n",
      "16/16 [==============================] - 0s 625us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 19/150\n",
      "16/16 [==============================] - 0s 524us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 20/150\n",
      "16/16 [==============================] - 0s 534us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 21/150\n",
      "16/16 [==============================] - 0s 546us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 22/150\n",
      "16/16 [==============================] - 0s 871us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 23/150\n",
      "16/16 [==============================] - 0s 873us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 24/150\n",
      "16/16 [==============================] - 0s 945us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 25/150\n",
      "16/16 [==============================] - 0s 933us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 26/150\n",
      "16/16 [==============================] - 0s 924us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 27/150\n",
      "16/16 [==============================] - 0s 875us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 28/150\n",
      "16/16 [==============================] - 0s 958us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 29/150\n",
      "16/16 [==============================] - 0s 997us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 30/150\n",
      "16/16 [==============================] - 0s 911us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 31/150\n",
      "16/16 [==============================] - 0s 983us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 32/150\n",
      "16/16 [==============================] - 0s 935us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 33/150\n",
      "16/16 [==============================] - 0s 949us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 34/150\n",
      "16/16 [==============================] - 0s 1ms/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 35/150\n",
      "16/16 [==============================] - 0s 1ms/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 36/150\n",
      "16/16 [==============================] - 0s 1ms/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 37/150\n",
      "16/16 [==============================] - 0s 935us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 38/150\n",
      "16/16 [==============================] - 0s 807us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 39/150\n",
      "16/16 [==============================] - 0s 688us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 40/150\n",
      "16/16 [==============================] - 0s 625us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 41/150\n",
      "16/16 [==============================] - 0s 623us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 42/150\n",
      "16/16 [==============================] - 0s 623us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 43/150\n",
      "16/16 [==============================] - 0s 621us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 44/150\n",
      "16/16 [==============================] - 0s 561us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 45/150\n",
      "16/16 [==============================] - 0s 625us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 46/150\n",
      "16/16 [==============================] - 0s 686us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 47/150\n",
      "16/16 [==============================] - 0s 687us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 48/150\n",
      "16/16 [==============================] - 0s 621us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 49/150\n",
      "16/16 [==============================] - 0s 703us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 50/150\n",
      "16/16 [==============================] - 0s 561us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 51/150\n",
      "16/16 [==============================] - 0s 672us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 52/150\n",
      "16/16 [==============================] - 0s 638us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 53/150\n",
      "16/16 [==============================] - 0s 664us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 54/150\n",
      "16/16 [==============================] - 0s 623us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 55/150\n",
      "16/16 [==============================] - 0s 631us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 56/150\n",
      "16/16 [==============================] - 0s 567us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 57/150\n",
      "16/16 [==============================] - 0s 637us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 58/150\n",
      "16/16 [==============================] - 0s 625us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 59/150\n",
      "16/16 [==============================] - 0s 561us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 60/150\n",
      "16/16 [==============================] - 0s 621us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 61/150\n",
      "16/16 [==============================] - 0s 623us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 62/150\n",
      "16/16 [==============================] - 0s 623us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 63/150\n",
      "16/16 [==============================] - 0s 579us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 64/150\n",
      "16/16 [==============================] - 0s 565us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 65/150\n",
      "16/16 [==============================] - 0s 611us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 66/150\n",
      "16/16 [==============================] - 0s 556us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 67/150\n",
      "16/16 [==============================] - 0s 859us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 68/150\n",
      "16/16 [==============================] - 0s 935us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 69/150\n",
      "16/16 [==============================] - 0s 935us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 70/150\n",
      "16/16 [==============================] - 0s 957us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 71/150\n",
      "16/16 [==============================] - 0s 873us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 72/150\n",
      "16/16 [==============================] - 0s 937us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 73/150\n",
      "16/16 [==============================] - 0s 825us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 74/150\n",
      "16/16 [==============================] - 0s 927us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 75/150\n",
      "16/16 [==============================] - 0s 872us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 76/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 1ms/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 77/150\n",
      "16/16 [==============================] - 0s 1ms/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 78/150\n",
      "16/16 [==============================] - 0s 997us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 79/150\n",
      "16/16 [==============================] - 0s 935us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 80/150\n",
      "16/16 [==============================] - 0s 928us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 81/150\n",
      "16/16 [==============================] - 0s 938us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 82/150\n",
      "16/16 [==============================] - 0s 882us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 83/150\n",
      "16/16 [==============================] - 0s 875us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 84/150\n",
      "16/16 [==============================] - 0s 873us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 85/150\n",
      "16/16 [==============================] - 0s 873us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 86/150\n",
      "16/16 [==============================] - 0s 821us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 87/150\n",
      "16/16 [==============================] - 0s 871us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 88/150\n",
      "16/16 [==============================] - 0s 875us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 89/150\n",
      "16/16 [==============================] - 0s 824us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 90/150\n",
      "16/16 [==============================] - 0s 868us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 91/150\n",
      "16/16 [==============================] - 0s 880us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 92/150\n",
      "16/16 [==============================] - 0s 805us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 93/150\n",
      "16/16 [==============================] - 0s 903us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 94/150\n",
      "16/16 [==============================] - 0s 874us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 95/150\n",
      "16/16 [==============================] - 0s 932us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 96/150\n",
      "16/16 [==============================] - 0s 938us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 97/150\n",
      "16/16 [==============================] - 0s 930us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 98/150\n",
      "16/16 [==============================] - 0s 880us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 99/150\n",
      "16/16 [==============================] - 0s 945us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 100/150\n",
      "16/16 [==============================] - 0s 933us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 101/150\n",
      "16/16 [==============================] - 0s 918us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 102/150\n",
      "16/16 [==============================] - 0s 812us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 103/150\n",
      "16/16 [==============================] - 0s 829us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 104/150\n",
      "16/16 [==============================] - 0s 873us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 105/150\n",
      "16/16 [==============================] - 0s 935us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 106/150\n",
      "16/16 [==============================] - 0s 873us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 107/150\n",
      "16/16 [==============================] - 0s 935us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 108/150\n",
      "16/16 [==============================] - 0s 871us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 109/150\n",
      "16/16 [==============================] - 0s 908us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 110/150\n",
      "16/16 [==============================] - 0s 935us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 111/150\n",
      "16/16 [==============================] - 0s 937us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 112/150\n",
      "16/16 [==============================] - 0s 873us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 113/150\n",
      "16/16 [==============================] - 0s 873us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 114/150\n",
      "16/16 [==============================] - 0s 873us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 115/150\n",
      "16/16 [==============================] - 0s 810us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 116/150\n",
      "16/16 [==============================] - 0s 748us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 117/150\n",
      "16/16 [==============================] - 0s 810us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 118/150\n",
      "16/16 [==============================] - 0s 649us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 119/150\n",
      "16/16 [==============================] - 0s 593us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 120/150\n",
      "16/16 [==============================] - 0s 566us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 121/150\n",
      "16/16 [==============================] - 0s 561us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 122/150\n",
      "16/16 [==============================] - 0s 561us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 123/150\n",
      "16/16 [==============================] - 0s 499us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 124/150\n",
      "16/16 [==============================] - 0s 497us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 125/150\n",
      "16/16 [==============================] - 0s 596us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 126/150\n",
      "16/16 [==============================] - 0s 436us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 127/150\n",
      "16/16 [==============================] - 0s 513us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 128/150\n",
      "16/16 [==============================] - 0s 501us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 129/150\n",
      "16/16 [==============================] - 0s 499us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 130/150\n",
      "16/16 [==============================] - 0s 483us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 131/150\n",
      "16/16 [==============================] - 0s 499us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 132/150\n",
      "16/16 [==============================] - 0s 492us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 133/150\n",
      "16/16 [==============================] - 0s 501us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 134/150\n",
      "16/16 [==============================] - 0s 561us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 135/150\n",
      "16/16 [==============================] - 0s 436us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 136/150\n",
      "16/16 [==============================] - 0s 561us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 137/150\n",
      "16/16 [==============================] - 0s 561us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 138/150\n",
      "16/16 [==============================] - 0s 483us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 139/150\n",
      "16/16 [==============================] - 0s 499us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 140/150\n",
      "16/16 [==============================] - 0s 503us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 141/150\n",
      "16/16 [==============================] - 0s 499us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 142/150\n",
      "16/16 [==============================] - 0s 561us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 143/150\n",
      "16/16 [==============================] - 0s 497us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 144/150\n",
      "16/16 [==============================] - 0s 509us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 145/150\n",
      "16/16 [==============================] - 0s 935us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 146/150\n",
      "16/16 [==============================] - 0s 935us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 147/150\n",
      "16/16 [==============================] - 0s 875us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 148/150\n",
      "16/16 [==============================] - 0s 997us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 149/150\n",
      "16/16 [==============================] - 0s 883us/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Epoch 150/150\n",
      "16/16 [==============================] - 0s 939us/sample - loss: -30.6665 - accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23364ee85c0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.add(Dense(12,input_dim=8,activation='relu'))\n",
    "model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(1,activation='softmax'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X, y, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "16/16 [==============================] - 0s 14ms/sample - loss: -30.6665 - accuracy: 0.5000\n",
      "Accuracy: 50.00\n"
     ]
    }
   ],
   "source": [
    "_, accuracy = model.evaluate(X, y)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "#from tensorflow.keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pandas.read_csv(\"iris.data\", header=None)\n",
    "dataset = dataframe.values\n",
    "X = dataset[:,0:4].astype(float)\n",
    "Y = dataset[:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y = np_utils.to_categorical(encoded_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "\t# create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8, input_dim=4, activation='relu'))\n",
    "    model.add(Dense(12, activation='relu'))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "\t# Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 150 samples\n",
      "150/150 [==============================] - 1s 7ms/sample - loss: 2.4350 - accuracy: 0.3333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23369a14518>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(8, input_dim=4, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\t# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X,dummy_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = KerasClassifier(build_fn=baseline_model, epochs=200, batch_size=5, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline: 97.33% (4.42%)\n"
     ]
    }
   ],
   "source": [
    "results = cross_val_score(estimator, X, dummy_y, cv=kfold)\n",
    "print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
