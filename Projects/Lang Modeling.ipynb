{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# spacy for lemmatization\n",
    "import spacy\n",
    "\n",
    "# Plotting tools\n",
    "#import pyLDAvis\n",
    "#import pyLDAvis.gensim  # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Enable logging for gensim - optional\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "\n",
    "#important libraries for NLP\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "from pytorch_transformers import XLNetModel, XLNetTokenizer, XLNetForSequenceClassification\n",
    "from pytorch_transformers import AdamW\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from bert_serving.client import BertClient\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertConfig\n",
    "from pytorch_pretrained_bert import BertForTokenClassification, BertAdam\n",
    "from tqdm import tqdm, trange\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import Word2Vec\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])\n",
    "import gensim\n",
    "from gensim import corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import XLNetTokenizer, XLNetLMHeadModel\n",
    "import torch\n",
    "\n",
    "tokenizer = XLNetTokenizer.from_pretrained('xlnet-large-cased')\n",
    "model = XLNetLMHeadModel.from_pretrained('xlnet-large-cased')\n",
    "\n",
    "# We show how to setup inputs to predict a next token using a bi-directional context.\n",
    "input_ids = torch.tensor(tokenizer.encode(\"Hello, my dog is very <mask>\", add_special_tokens=False)).unsqueeze(0)  # We will predict the masked token\n",
    "perm_mask = torch.zeros((1, input_ids.shape[1], input_ids.shape[1]), dtype=torch.float)\n",
    "perm_mask[:, :, -1] = 1.0  # Previous tokens don't see last token\n",
    "target_mapping = torch.zeros((1, 1, input_ids.shape[1]), dtype=torch.float)  # Shape [1, 1, seq_length] => let's predict one token\n",
    "target_mapping[0, 0, -1] = 1.0  # Our first (and only) prediction will be the last token of the sequence (the masked token)\n",
    "\n",
    "outputs = model(input_ids, perm_mask=perm_mask, target_mapping=target_mapping)\n",
    "next_token_logits = outputs[0]  # Output has shape [target_mapping.size(0), target_mapping.size(1), config.vocab_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.tensor(tokenizer.encode(\"Hello, my dog is very <mask>\", add_special_tokens=False)).unsqueeze(0)  # We will predict the masked token\n",
    "perm_mask = torch.zeros((1, input_ids.shape[1], input_ids.shape[1]), dtype=torch.float)\n",
    "perm_mask[:, :, -1] = 1.0  # Previous tokens don't see last token\n",
    "target_mapping = torch.zeros((1, 1, input_ids.shape[1]), dtype=torch.float)  # Shape [1, 1, seq_length] => let's predict one token\n",
    "target_mapping[0, 0, -1] = 1.0  # Our first (and only) prediction will be the last token of the sequence (the masked token)\n",
    "\n",
    "outputs = model(input_ids, perm_mask=perm_mask, target_mapping=target_mapping)\n",
    "next_token_logits = outputs[0]  # Output has shape [target_mapping.size(0), target_mapping.size(1), config.vocab_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.tensor(tokenizer.encode(\"Hello, my dog is very <mask>\", add_special_tokens=False)).unsqueeze(0)  # We will predict the masked token\n",
    "labels = torch.tensor(tokenizer.encode(\"cute\", add_special_tokens=False)).unsqueeze(0)\n",
    "assert labels.shape[0] == 1, 'only one word will be predicted'\n",
    "perm_mask = torch.zeros((1, input_ids.shape[1], input_ids.shape[1]), dtype=torch.float)\n",
    "perm_mask[:, :, -1] = 1.0  # Previous tokens don't see last token as is done in standard auto-regressive lm training\n",
    "target_mapping = torch.zeros((1, 1, input_ids.shape[1]), dtype=torch.float)  # Shape [1, 1, seq_length] => let's predict one token\n",
    "target_mapping[0, 0, -1] = 1.0  # Our first (and only) prediction will be the last token of the sequence (the masked token)\n",
    "\n",
    "outputs = model(input_ids, perm_mask=perm_mask, target_mapping=target_mapping, labels=labels)\n",
    "loss, next_token_logits = outputs[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32000"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm_mask = torch.zeros((1, input_ids.shape[1], input_ids.shape[1]), dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_mapping = torch.zeros((1, 1, input_ids.shape[1]), dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_mapping[0, 0, 1] = 1.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 1., 0., 0., 0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForNextSentencePrediction\n",
    "import torch\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForNextSentencePrediction.from_pretrained('bert-base-uncased')\n",
    "\n",
    "input_ids = torch.tensor(tokenizer.encode(\"Hello, my dog is cute\", add_special_tokens=True)).unsqueeze(0)  # Batch size 1\n",
    "outputs = model(input_ids)\n",
    "\n",
    "seq_relationship_scores = outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.3474, -2.0613]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_relationship_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method PreTrainedModel.get_input_embeddings of BertForNextSentencePrediction(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (cls): BertOnlyNSPHead(\n",
       "    (seq_relationship): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_input_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import XLNetTokenizer, XLNetForTokenClassification,XLNetConfig\n",
    "import torch\n",
    "\n",
    "tokenizer = XLNetTokenizer.from_pretrained('xlnet-large-cased')\n",
    "model = XLNetForTokenClassification.from_pretrained('xlnet-large-cased')\n",
    "configuration = XLNetConfig()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "configuration.output_attentions=True\n",
    "input_ids = torch.tensor(tokenizer.encode(\"Hello, my dog is cute\")).unsqueeze(0)  # Batch size 1\n",
    "labels = torch.tensor([1] * input_ids.size(1)).unsqueeze(0)  # Batch size 1\n",
    "outputs = model(input_ids)\n",
    "\n",
    "scores = outputs[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ -6.5340,   7.2504],\n",
       "         [ -8.5421,   9.3108],\n",
       "         [-12.2136,  10.5035],\n",
       "         [ -5.8214,   5.7031],\n",
       "         [ -8.4494,   7.4346],\n",
       "         [ -2.9133,   2.3670],\n",
       "         [ -7.0038,   6.8811],\n",
       "         [ -6.8342,   6.0932],\n",
       "         [ -7.6849,   9.4484]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import XLNetTokenizer, XLNetForMultipleChoice\n",
    "import torch\n",
    "\n",
    "tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased')\n",
    "model = XLNetForMultipleChoice.from_pretrained('xlnet-base-cased')\n",
    "\n",
    "choices = [\"Hello, my dog is cute\", \"Hello, my cat is amazing\"]\n",
    "input_ids = torch.tensor([tokenizer.encode(s) for s in choices]).unsqueeze(0)  # Batch size 1, 2 choices\n",
    "labels = torch.tensor(1).unsqueeze(0)  # Batch size 1\n",
    "\n",
    "outputs = model(input_ids, labels=labels)\n",
    "loss, classification_scores = outputs[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.7156, grad_fn=<NllLossBackward>),\n",
       " tensor([[0.3204, 0.2760]], grad_fn=<ViewBackward>))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import XLNetTokenizer, XLNetModel\n",
    "import torch\n",
    "\n",
    "tokenizer = XLNetTokenizer.from_pretrained('xlnet-large-cased')\n",
    "model = XLNetModel.from_pretrained('xlnet-large-cased')\n",
    "\n",
    "input_ids = torch.tensor(tokenizer.encode(\"Hello, my dog is cute\", add_special_tokens=False)).unsqueeze(0)  # Batch size 1\n",
    "\n",
    "outputs = model(input_ids)\n",
    "last_hidden_states = outputs[0]  # The last hidden-state is the first element of the output tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.2713, -2.2821,  0.3375,  ..., -3.8316,  0.3944,  4.2570],\n",
       "         [-0.0071, -3.1399,  1.8038,  ..., -2.9843, -0.9836,  5.6646],\n",
       "         [-0.4040, -4.1377,  1.6515,  ..., -2.2477, -1.6044,  3.6061],\n",
       "         ...,\n",
       "         [-0.2540, -4.8292,  0.7840,  ..., -1.7736, -0.3579,  6.3014],\n",
       "         [ 0.5639, -4.3388,  1.1392,  ..., -1.9836, -0.8785,  4.1125],\n",
       "         [ 1.1783, -4.5430,  1.0778,  ..., -2.3407, -0.8741,  4.6008]]],\n",
       "       grad_fn=<PermuteBackward>)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "tokenizer = XLNetTokenizer.from_pretrained('xlnet-large-cased')\n",
    "model = XLNetLMHeadModel.from_pretrained('xlnet-large-cased')\n",
    "\n",
    "# We show how to setup inputs to predict a next token using a bi-directional context.\n",
    "input_ids = torch.tensor(tokenizer.encode(\"Hello, my dog is very <mask>\", add_special_tokens=False)).unsqueeze(0)  # We will predict the masked token\n",
    "perm_mask = torch.zeros((1, input_ids.shape[1], input_ids.shape[1]), dtype=torch.float)\n",
    "perm_mask[:, :, -1] = 1.0  # Previous tokens don't see last token\n",
    "target_mapping = torch.zeros((1, 1, input_ids.shape[1]), dtype=torch.float)  # Shape [1, 1, seq_length] => let's predict one token\n",
    "target_mapping[0, 0, -1] = 1.0  # Our first (and only) prediction will be the last token of the sequence (the masked token)\n",
    "\n",
    "outputs = model(input_ids, perm_mask=perm_mask, target_mapping=target_mapping)\n",
    "next_token_logits = outputs[0]  # Output has shape [target_mapping.size(0), target_mapping.size(1), config.vocab_size]\n",
    "\n",
    "# The same way can the XLNetLMHeadModel be used to be trained by standard auto-regressive language modeling.\n",
    "input_ids = torch.tensor(tokenizer.encode(\"Hello, my dog is very <mask>\", add_special_tokens=False)).unsqueeze(0)  # We will predict the masked token\n",
    "labels = torch.tensor(tokenizer.encode(\"cute\", add_special_tokens=False)).unsqueeze(0)\n",
    "assert labels.shape[0] == 1, 'only one word will be predicted'\n",
    "perm_mask = torch.zeros((1, input_ids.shape[1], input_ids.shape[1]), dtype=torch.float)\n",
    "perm_mask[:, :, -1] = 1.0  # Previous tokens don't see last token as is done in standard auto-regressive lm training\n",
    "target_mapping = torch.zeros((1, 1, input_ids.shape[1]), dtype=torch.float)  # Shape [1, 1, seq_length] => let's predict one token\n",
    "target_mapping[0, 0, -1] = 1.0  # Our first (and only) prediction will be the last token of the sequence (the masked token)\n",
    "\n",
    "outputs = model(input_ids, perm_mask=perm_mask, target_mapping=target_mapping, labels=labels)\n",
    "loss, next_token_logits = outputs[:2]  # Output has shape [target_mapping.size(0), target_mapping.size(1), config.vocab_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method XLNetLMHeadModel.get_output_embeddings of XLNetLMHeadModel(\n",
       "  (transformer): XLNetModel(\n",
       "    (word_embedding): Embedding(32000, 1024)\n",
       "    (layer): ModuleList(\n",
       "      (0): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1)\n",
       "      )\n",
       "      (1): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1)\n",
       "      )\n",
       "      (2): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1)\n",
       "      )\n",
       "      (3): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1)\n",
       "      )\n",
       "      (4): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1)\n",
       "      )\n",
       "      (5): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1)\n",
       "      )\n",
       "      (6): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1)\n",
       "      )\n",
       "      (7): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1)\n",
       "      )\n",
       "      (8): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1)\n",
       "      )\n",
       "      (9): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1)\n",
       "      )\n",
       "      (10): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1)\n",
       "      )\n",
       "      (11): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1)\n",
       "      )\n",
       "      (12): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1)\n",
       "      )\n",
       "      (13): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1)\n",
       "      )\n",
       "      (14): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1)\n",
       "      )\n",
       "      (15): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1)\n",
       "      )\n",
       "      (16): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1)\n",
       "      )\n",
       "      (17): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1)\n",
       "      )\n",
       "      (18): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1)\n",
       "      )\n",
       "      (19): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1)\n",
       "      )\n",
       "      (20): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1)\n",
       "      )\n",
       "      (21): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1)\n",
       "      )\n",
       "      (22): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1)\n",
       "      )\n",
       "      (23): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1)\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1)\n",
       "  )\n",
       "  (lm_loss): Linear(in_features=1024, out_features=32000, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_output_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import XLNetTokenizer, XLNetForSequenceClassification\n",
    "import torch\n",
    "\n",
    "tokenizer = XLNetTokenizer.from_pretrained('xlnet-large-cased')\n",
    "model = XLNetForSequenceClassification.from_pretrained('xlnet-large-cased')\n",
    "\n",
    "input_ids = torch.tensor(tokenizer.encode(\"Hello, my dog is cute\", add_special_tokens=True)).unsqueeze(0)  # Batch size 1\n",
    "labels = torch.tensor([1]).unsqueeze(0)  # Batch size 1\n",
    "outputs = model(input_ids, labels=labels)\n",
    "loss, logits = outputs[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import XLNetTokenizer, XLNetModel\n",
    "import torch\n",
    "\n",
    "tokenizer = XLNetTokenizer.from_pretrained('xlnet-large-cased')\n",
    "model = XLNetModel.from_pretrained('xlnet-large-cased')\n",
    "\n",
    "input_ids = torch.tensor(tokenizer.encode(\"Hello, my dog is cute\", add_special_tokens=False)).unsqueeze(0)  # Batch size 1\n",
    "\n",
    "outputs = model(input_ids)\n",
    "last_hidden_states = outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.2713, -2.2821,  0.3375,  ..., -3.8316,  0.3944,  4.2570],\n",
       "         [-0.0071, -3.1399,  1.8038,  ..., -2.9843, -0.9836,  5.6646],\n",
       "         [-0.4040, -4.1377,  1.6515,  ..., -2.2477, -1.6044,  3.6061],\n",
       "         ...,\n",
       "         [-0.2540, -4.8292,  0.7840,  ..., -1.7736, -0.3579,  6.3014],\n",
       "         [ 0.5639, -4.3388,  1.1392,  ..., -1.9836, -0.8785,  4.1125],\n",
       "         [ 1.1783, -4.5430,  1.0778,  ..., -2.3407, -0.8741,  4.6008]]],\n",
       "       grad_fn=<PermuteBackward>)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
